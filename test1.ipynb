{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama \n",
    "\n",
    "prompt = \"Hello,ollama , give mahindra  car parts\"\n",
    "response = ollama.chat(model=\"qwen2.5vl:7b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030da6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "def pdf_to_images_bytes(pdf_path):\n",
    "    \"\"\"Convert all PDF pages to JPEG image bytes.\"\"\"\n",
    "    pages = convert_from_path(pdf_path, dpi=150)\n",
    "    image_bytes_list = []\n",
    "    for i, page in enumerate(pages):\n",
    "        buf = BytesIO()\n",
    "        page.save(buf, format=\"JPEG\")\n",
    "        image_bytes_list.append(buf.getvalue())\n",
    "    return image_bytes_list\n",
    "\n",
    "\n",
    "def extract_passport_from_pdf(pdf_path: str, model_name=\"qwen2.5vl:7b\"):\n",
    "    print(f\"\\n Processing PDF: {pdf_path}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    image_bytes_list = pdf_to_images_bytes(pdf_path)\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are a senior OCR document understanding model.\n",
    "    Analyze the uploaded passport or visa page image(s).\n",
    "\n",
    "    Rules:\n",
    "    - Keep both Arabic and English text exactly as visible.\n",
    "    - Do NOT translate.\n",
    "    - If a label (key) exists in both Arabic and English, combine them using \" / \".\n",
    "    - If a value exists in both Arabic and English, also combine them using \" / \".\n",
    "    - Output must be valid JSON only, no explanations.\n",
    "    - Don't skip any visible fields â€” include all possible fields.\n",
    "\n",
    "    Example format:\n",
    "    {\n",
    "      \"ID Number / Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©\": \"784199787632597\",\n",
    "      \"File No / Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù\": \"201/2023/7/663922\",\n",
    "      \"Passport No / Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ø²\": \"VT1337002\",\n",
    "      \"Name / Ø§Ù„Ø§Ø³Ù…\": \"MUHAMMAD AMIR IQBAL MUHAMMAD I / Ù…Ø­Ù…Ø¯ Ø§Ù…ÙŠØ± Ø§Ù‚Ø¨Ø§Ù„ Ù…Ø­Ù…Ø¯ Ø§Ù‚Ø¨Ø§Ù„\",\n",
    "      \"Profession / Ø§Ù„Ù…Ù‡Ù†Ø©\": \"PARTNER / Ø´Ø±ÙŠÙƒ\",\n",
    "      \"Employer / ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„\": \"H S P INTERNATIONAL FOODSTUFF TRADING L.L.C / Ø§ØªØ´ Ø§Ø³ Ø¨ÙŠ Ø§Ù†ØªØ±Ù†Ø§Ø´ÙˆÙ†Ø§Ù„ Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ© Ø´ Ø° Ù… Ù…\",\n",
    "      \"Place of Issue / Ø¬Ù‡Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±\": \"Ø¯Ø¨ÙŠ\",\n",
    "      \"Issue Date / ØªØ§Ø±ÙŠØ® Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"15/11/2023\",\n",
    "      \"Expiry Date / ØªØ§Ø±ÙŠØ® Ø¥Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"14/11/2025\",\n",
    "      \"Country / Ø§Ù„Ø¯ÙˆÙ„Ø©\": \"UNITED ARAB EMIRATES / Ø¯ÙˆÙ„Ø© Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©\",\n",
    "      \"Type / Ù†ÙˆØ¹ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"RESIDENCE / Ø¥Ù‚Ø§Ù…Ø©\"\n",
    "    }\n",
    "\n",
    "    Only output JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Running model inference on all pages together...\")\n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "                \"images\": image_bytes_list\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    content = response[\"message\"][\"content\"]\n",
    "\n",
    "    # Try to safely parse JSON\n",
    "    try:\n",
    "        match = re.search(r\"(\\{[\\s\\S]*\\})\", content)\n",
    "        data = json.loads(match.group(1)) if match else {\"raw_text\": content}\n",
    "    except Exception as e:\n",
    "        data = {\"raw_text\": content, \"error\": str(e)}\n",
    "\n",
    "    output = {\"file\": str(pdf_path), \"extracted_data\": data}\n",
    "    print(f\"\\n Extraction completed in {time.time() - start_time:.2f} seconds.\")\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad192768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing PDF: D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.pdf\n",
      " Running model inference on all pages together...\n",
      "\n",
      " Extraction completed in 102.00 seconds.\n",
      "{\n",
      "  \"file\": \"D:\\\\AI Projects\\\\passport_extraction\\\\passport\\\\2.In house PL 31.03.2025.pdf\",\n",
      "  \"extracted_data\": {\n",
      "    \"PARTICULARS / Ø§Ù„Ù…Ø®ØµØµØ§Øª\": \"TOTAL COMPREHENSIVE INCOME FOR THE YEAR / Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø³Ù†Ø©\",\n",
      "    \"Amount [AED] / Ø§Ù„Ù…Ø¨Ù„Øº [Ø¯Ø±Ù‡Ù… Ø¥Ù…Ø§Ø±Ø§ØªÙŠ]\": \"1,541,978 / 1,541,978\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pdf_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.pdf\")  # <-- change to your file path\n",
    "result = extract_passport_from_pdf(pdf_path)\n",
    "\n",
    "# Display nicely formatted output\n",
    "import json\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d8d71",
   "metadata": {},
   "source": [
    "below code stored data in json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6305d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing PDF: D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.pdf\n",
      "Running model inference on all pages together...\n",
      "\n",
      " Extraction completed in 37.70 seconds.\n",
      " Output saved to: D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.json\n",
      "{\n",
      "  \"file\": \"D:\\\\AI Projects\\\\passport_extraction\\\\passport\\\\2.In house PL 31.03.2025.pdf\",\n",
      "  \"extracted_data\": {\n",
      "    \"PARTICULARS / Ø§Ù„Ù…Ø®ØµØµØ§Øª\": \"TOTAL COMPREHENSIVE INCOME FOR THE YEAR / Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø³Ù†Ø©\",\n",
      "    \"Amount [AED] / Ø§Ù„Ù…Ø¨Ù„Øº [Ø¯Ø±Ù‡Ù… Ø¥Ù…Ø§Ø±Ø§ØªÙŠ]\": \"1,541,978\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "def pdf_to_images_bytes(pdf_path):\n",
    "    \"\"\"Convert all PDF pages to JPEG image bytes.\"\"\"\n",
    "    pages = convert_from_path(pdf_path, dpi=150)\n",
    "    image_bytes_list = []\n",
    "    for i, page in enumerate(pages):\n",
    "        buf = BytesIO()\n",
    "        page.save(buf, format=\"JPEG\")\n",
    "        image_bytes_list.append(buf.getvalue())\n",
    "    return image_bytes_list\n",
    "\n",
    "\n",
    "def extract_passport_from_pdf(pdf_path: str, model_name=\"qwen2.5vl:7b\"):\n",
    "    print(f\"\\nProcessing PDF: {pdf_path}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    image_bytes_list = pdf_to_images_bytes(pdf_path)\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are a senior OCR document understanding model.\n",
    "    Analyze the uploaded passport or visa page image(s).\n",
    "\n",
    "    Rules:\n",
    "    - Keep both Arabic and English text exactly as visible.\n",
    "    - if no arabic words are present just keep english text as is.\n",
    "    - Do NOT translate.\n",
    "    - If a label (key) exists in both Arabic and English, combine them using \" / \".\n",
    "    - If a value exists in both Arabic and English, also combine them using \" / \".\n",
    "    - Output must be valid JSON only, no explanations.\n",
    "    - Don't skip any visible fields â€” include all possible fields.\n",
    "\n",
    "    Example format:\n",
    "    {\n",
    "      \"ID Number / Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©\": \"784199787632597\",\n",
    "      \"File No / Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù\": \"201/2023/7/663922\",\n",
    "      \"Passport No / Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ø²\": \"VT1337002\",\n",
    "      \"Name / Ø§Ù„Ø§Ø³Ù…\": \"MUHAMMAD AMIR IQBAL MUHAMMAD I / Ù…Ø­Ù…Ø¯ Ø§Ù…ÙŠØ± Ø§Ù‚Ø¨Ø§Ù„ Ù…Ø­Ù…Ø¯ Ø§Ù‚Ø¨Ø§Ù„\",\n",
    "      \"Profession / Ø§Ù„Ù…Ù‡Ù†Ø©\": \"PARTNER / Ø´Ø±ÙŠÙƒ\",\n",
    "      \"Employer / ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„\": \"H S P INTERNATIONAL FOODSTUFF TRADING L.L.C / Ø§ØªØ´ Ø§Ø³ Ø¨ÙŠ Ø§Ù†ØªØ±Ù†Ø§Ø´ÙˆÙ†Ø§Ù„ Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ© Ø´ Ø° Ù… Ù…\",\n",
    "      \"Place of Issue / Ø¬Ù‡Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±\": \"Ø¯Ø¨ÙŠ\",\n",
    "      \"Issue Date / ØªØ§Ø±ÙŠØ® Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"15/11/2023\",\n",
    "      \"Expiry Date / ØªØ§Ø±ÙŠØ® Ø¥Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"14/11/2025\",\n",
    "      \"Country / Ø§Ù„Ø¯ÙˆÙ„Ø©\": \"UNITED ARAB EMIRATES / Ø¯ÙˆÙ„Ø© Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©\",\n",
    "      \"Type / Ù†ÙˆØ¹ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"RESIDENCE / Ø¥Ù‚Ø§Ù…Ø©\"\n",
    "    }\n",
    "\n",
    "    Only output JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Running model inference on all pages together...\")\n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "                \"images\": image_bytes_list\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    content = response[\"message\"][\"content\"]\n",
    "\n",
    "    # Try to safely parse JSON\n",
    "    try:\n",
    "        match = re.search(r\"(\\{[\\s\\S]*\\})\", content)\n",
    "        data = json.loads(match.group(1)) if match else {\"raw_text\": content}\n",
    "    except Exception as e:\n",
    "        data = {\"raw_text\": content, \"error\": str(e)}\n",
    "\n",
    "    output = {\"file\": str(pdf_path), \"extracted_data\": data}\n",
    "\n",
    "    # Save to a separate JSON file\n",
    "    output_file = Path(pdf_path).with_suffix(\".json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\n Extraction completed in {time.time() - start_time:.2f} seconds.\")\n",
    "    print(f\" Output saved to: {output_file}\")\n",
    "    return output\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pdf_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.pdf\")\n",
    "result = extract_passport_from_pdf(pdf_path)\n",
    "\n",
    "# Optional: print the JSON content on screen\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216a91d",
   "metadata": {},
   "source": [
    "below code is checking for getting perfect output of json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "def pdf_to_images_bytes(pdf_path):\n",
    "    \"\"\"Convert all PDF pages to JPEG image bytes.\"\"\"\n",
    "    pages = convert_from_path(pdf_path, dpi=150)\n",
    "    image_bytes_list = []\n",
    "    for i, page in enumerate(pages):\n",
    "        buf = BytesIO()\n",
    "        page.save(buf, format=\"JPEG\")\n",
    "        image_bytes_list.append(buf.getvalue())\n",
    "    return image_bytes_list\n",
    "\n",
    "\n",
    "def extract_passport_from_pdf(pdf_path: str, model_name=\"qwen2.5vl:7b\"):\n",
    "    print(f\"\\nProcessing PDF: {pdf_path}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    image_bytes_list = pdf_to_images_bytes(pdf_path)\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are a senior OCR document understanding model.\n",
    "    Analyze the uploaded passport or visa page image(s).\n",
    "\n",
    "    Rules:\n",
    "    - Keep both Arabic and English text exactly as visible.\n",
    "    - if no arabic words are present just keep english text as is.\n",
    "    - Do NOT translate.\n",
    "    - If a label (key) exists in both Arabic and English, combine them using \" / \".\n",
    "    - If a value exists in both Arabic and English, also combine them using \" / \".\n",
    "    - Output must be valid JSON only, no explanations.\n",
    "    - Don't skip any visible fields â€” include all possible fields.\n",
    "\n",
    "    Example format:\n",
    "    {\n",
    "      \"ID Number / Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©\": \"784199787632597\",\n",
    "      \"File No / Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù\": \"201/2023/7/663922\",\n",
    "      \"Passport No / Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ø²\": \"VT1337002\",\n",
    "      \"Name / Ø§Ù„Ø§Ø³Ù…\": \"MUHAMMAD AMIR IQBAL MUHAMMAD I / Ù…Ø­Ù…Ø¯ Ø§Ù…ÙŠØ± Ø§Ù‚Ø¨Ø§Ù„ Ù…Ø­Ù…Ø¯ Ø§Ù‚Ø¨Ø§Ù„\",\n",
    "      \"Profession / Ø§Ù„Ù…Ù‡Ù†Ø©\": \"PARTNER / Ø´Ø±ÙŠÙƒ\",\n",
    "      \"Employer / ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„\": \"H S P INTERNATIONAL FOODSTUFF TRADING L.L.C / Ø§ØªØ´ Ø§Ø³ Ø¨ÙŠ Ø§Ù†ØªØ±Ù†Ø§Ø´ÙˆÙ†Ø§Ù„ Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ© Ø´ Ø° Ù… Ù…\",\n",
    "      \"Place of Issue / Ø¬Ù‡Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±\": \"Ø¯Ø¨ÙŠ\",\n",
    "      \"Issue Date / ØªØ§Ø±ÙŠØ® Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"15/11/2023\",\n",
    "      \"Expiry Date / ØªØ§Ø±ÙŠØ® Ø¥Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"14/11/2025\",\n",
    "      \"Country / Ø§Ù„Ø¯ÙˆÙ„Ø©\": \"UNITED ARAB EMIRATES / Ø¯ÙˆÙ„Ø© Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©\",\n",
    "      \"Type / Ù†ÙˆØ¹ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"RESIDENCE / Ø¥Ù‚Ø§Ù…Ø©\"\n",
    "    }\n",
    "\n",
    "    Only output JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Running model inference on all pages together...\")\n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "                \"images\": image_bytes_list\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    content = response[\"message\"][\"content\"]\n",
    "\n",
    "    # Try to safely parse JSON\n",
    "    try:\n",
    "        match = re.search(r\"(\\{[\\s\\S]*\\})\", content)\n",
    "        data = json.loads(match.group(1)) if match else {\"raw_text\": content}\n",
    "    except Exception as e:\n",
    "        data = {\"raw_text\": content, \"error\": str(e)}\n",
    "\n",
    "    output = {\"file\": str(pdf_path), \"extracted_data\": data}\n",
    "\n",
    "    # Save to a separate JSON file\n",
    "    output_file = Path(pdf_path).with_suffix(\".json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\n Extraction completed in {time.time() - start_time:.2f} seconds.\")\n",
    "    print(f\" Output saved to: {output_file}\")\n",
    "    return output\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pdf_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.pdf\")\n",
    "result = extract_passport_from_pdf(pdf_path)\n",
    "\n",
    "# Optional: print the JSON content on screen\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6700d1a",
   "metadata": {},
   "source": [
    "below code is python script for template making "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57568f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Downloading reportlab-4.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from reportlab) (12.0.0)\n",
      "Collecting charset-normalizer (from reportlab)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Downloading reportlab-4.4.4-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 19.2 MB/s eta 0:00:00\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Installing collected packages: charset-normalizer, reportlab\n",
      "\n",
      "   ---------------------------------------- 0/2 [charset-normalizer]\n",
      "   ---------------------------------------- 0/2 [charset-normalizer]\n",
      "   ---------------------------------------- 0/2 [charset-normalizer]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   -------------------- ------------------- 1/2 [reportlab]\n",
      "   ---------------------------------------- 2/2 [reportlab]\n",
      "\n",
      "Successfully installed charset-normalizer-3.4.4 reportlab-4.4.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7648966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib import colors\n",
    "import json\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02f8fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID Number / Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©': '784199787632597',\n",
       " 'File No / Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù': '201/2023/7/663922',\n",
       " 'Passport No / Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ø²': 'VT1337002',\n",
       " 'Name / Ø§Ù„Ø§Ø³Ù…': 'MUHAMMAD AMIR IQBAL MUHAMMAD I / Ù…Ø­Ù…Ø¯ Ø§Ù…ÙŠØ± Ø§Ù‚Ø¨Ø§Ù„ Ù…Ø­Ù…Ø¯ Ø§Ù‚Ø¨Ø§Ù„',\n",
       " 'Profession / Ø§Ù„Ù…Ù‡Ù†Ø©': 'PARTNER / Ø´Ø±ÙŠÙƒ',\n",
       " 'Employer / ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„': 'H S P INTERNATIONAL FOODSTUFF TRADING L.L.C / Ø§ØªØ´ Ø§Ø³ Ø¨ÙŠ Ø§Ù†ØªØ±Ù†Ø§Ø´ÙˆÙ†Ø§Ù„ Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ© Ø´ Ø° Ù… Ù…',\n",
       " 'Place of Issue / Ø¬Ù‡Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±': 'Ø¯Ø¨ÙŠ',\n",
       " 'Issue Date / ØªØ§Ø±ÙŠØ® Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©': '15/11/2023',\n",
       " 'Expiry Date / ØªØ§Ø±ÙŠØ® Ø¥Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©': '14/11/2025',\n",
       " 'Country / Ø§Ù„Ø¯ÙˆÙ„Ø©': 'UNITED ARAB EMIRATES / Ø¯ÙˆÙ„Ø© Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©',\n",
       " 'Type / Ù†ÙˆØ¹ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©': 'RESIDENCE / Ø¥Ù‚Ø§Ù…Ø©'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the previously extracted JSON file\n",
    "json_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\VISA_61734560.json\")\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "extracted_data = data.get(\"extracted_data\", {})\n",
    "extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d04773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_passport_template(output_pdf_path, extracted_data):\n",
    "    # Convert Path object to string if needed\n",
    "    if isinstance(output_pdf_path, Path):\n",
    "        output_pdf_path = str(output_pdf_path)\n",
    "\n",
    "    doc = SimpleDocTemplate(output_pdf_path, pagesize=A4)\n",
    "    elements = []\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = styles['Heading1']\n",
    "    normal_style = styles['Normal']\n",
    "\n",
    "    # Title\n",
    "    elements.append(Paragraph(\"Passport / Visa Extracted Details\", title_style))\n",
    "    elements.append(Spacer(1, 20))\n",
    "\n",
    "    # Convert extracted JSON into table format\n",
    "    data_list = [[\"Field\", \"Value\"]]\n",
    "    for key, value in extracted_data.items():\n",
    "        # Ensure all values are strings (in case of None or numeric)\n",
    "        data_list.append([str(key), str(value)])\n",
    "\n",
    "    # Create table\n",
    "    table = Table(data_list, colWidths=[200, 330])\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 10),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.25, colors.black),\n",
    "    ]))\n",
    "\n",
    "    elements.append(table)\n",
    "    doc.build(elements)\n",
    "\n",
    "    print(f\" PDF template created successfully: {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6525c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PDF template created successfully: filled_passport_template.pdf\n"
     ]
    }
   ],
   "source": [
    "output_pdf = Path(r\"filled_passport_template.pdf\")\n",
    "create_passport_template(output_pdf, extracted_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4887302a",
   "metadata": {},
   "source": [
    "generate empty template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d55387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.units import inch\n",
    "from pathlib import Path\n",
    "\n",
    "def create_empty_passport_template(output_pdf_path):\n",
    "    c = canvas.Canvas(str(output_pdf_path), pagesize=A4)\n",
    "    width, height = A4\n",
    "\n",
    "    # Title\n",
    "    c.setFont(\"Helvetica-Bold\", 18)\n",
    "    c.drawCentredString(width / 2, height - 60, \"Passport / Visa Data Page Template\")\n",
    "\n",
    "    # Subtitle\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "    c.drawCentredString(width / 2, height - 80, \"(For Automated Data Filling System)\")\n",
    "\n",
    "    # Starting coordinates\n",
    "    x_label = 60\n",
    "    x_field = 250\n",
    "    y_start = height - 130\n",
    "    line_height = 40\n",
    "\n",
    "    fields = [\n",
    "        (\"Passport No / Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ø²\",),\n",
    "        (\"Name / Ø§Ù„Ø§Ø³Ù…\",),\n",
    "        (\"Nationality / Ø§Ù„Ø¬Ù†Ø³ÙŠØ©\",),\n",
    "        (\"Date of Birth / ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯\",),\n",
    "        (\"Place of Issue / Ø¬Ù‡Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±\",),\n",
    "        (\"Issue Date / ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø±\",),\n",
    "        (\"Expiry Date / ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡\",),\n",
    "        (\"Profession / Ø§Ù„Ù…Ù‡Ù†Ø©\",),\n",
    "        (\"Employer / ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„\",),\n",
    "        (\"Country / Ø§Ù„Ø¯ÙˆÙ„Ø©\",)\n",
    "    ]\n",
    "\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "\n",
    "    for i, (label,) in enumerate(fields):\n",
    "        y = y_start - i * line_height\n",
    "        c.drawString(x_label, y, f\"{label} :\")\n",
    "        c.line(x_field, y - 2, width - 60, y - 2)  # Draw line for data\n",
    "\n",
    "    # Border Box\n",
    "    c.setLineWidth(2)\n",
    "    c.rect(50, y_start - len(fields) * line_height - 20, width - 100, len(fields) * line_height + 50, stroke=1, fill=0)\n",
    "\n",
    "    # Footer\n",
    "    c.setFont(\"Helvetica-Oblique\", 9)\n",
    "    c.drawRightString(width - 60, 40, \"Generated by Passport Extraction System\")\n",
    "\n",
    "    c.save()\n",
    "    print(f\"âœ… Empty passport template created at: {output_pdf_path}\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e75b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Empty passport template created at: D:\\AI Projects\\passport_extraction\\passport\\passport_template_empty.pdf\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\passport_template_empty.pdf\")\n",
    "create_empty_passport_template(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1373f",
   "metadata": {},
   "source": [
    "Use your extracted JSON + LLM to automatically map and fill values inside this template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287ae143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import ollama, json\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a86c750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PARTICULARS / Ø§Ù„Ù…Ø®ØµØµØ§Øª': 'TOTAL COMPREHENSIVE INCOME FOR THE YEAR / Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø³Ù†Ø©',\n",
       " 'Amount [AED] / Ø§Ù„Ù…Ø¨Ù„Øº [Ø¯Ø±Ù‡Ù… Ø¥Ù…Ø§Ø±Ø§ØªÙŠ]': '1,541,978'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths\n",
    "json_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.json\")\n",
    "template_pdf = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\passport_template_empty.pdf\")\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    extracted_data = json.load(f).get(\"extracted_data\", {})\n",
    "\n",
    "# ---- Optional: ask the LLM to normalize key names ----\n",
    "prompt = f\"\"\"\n",
    "You are a mapping assistant. Match the JSON keys to these template fields:\n",
    "\n",
    "[\"Passport No\", \"Name\", \"Nationality\", \"Date of Birth\", \"Place of Issue\",\n",
    " \"Issue Date\", \"Expiry Date\", \"Profession\", \"Employer\", \"Country\"]\n",
    "\n",
    "Return JSON with this format:\n",
    "{{\n",
    "  \"Passport No\": \"<value>\",\n",
    "  \"Name\": \"<value>\",\n",
    "  ...\n",
    "}}\n",
    "JSON input:\n",
    "{json.dumps(extracted_data, ensure_ascii=False, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(model=\"qwen2.5:7b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "mapped_data_text = response[\"message\"][\"content\"]\n",
    "\n",
    "try:\n",
    "    mapped_data = json.loads(mapped_data_text)\n",
    "except Exception:\n",
    "    mapped_data = extracted_data  # fallback if parsing fails\n",
    "\n",
    "mapped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1afa1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_passport_template(empty_pdf_path, output_pdf_path, data):\n",
    "    reader = PdfReader(str(empty_pdf_path))\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    # Get template page\n",
    "    page = reader.pages[0]\n",
    "    packet_path = output_pdf_path.with_suffix(\".overlay.pdf\")\n",
    "\n",
    "    width, height = A4\n",
    "    c = canvas.Canvas(str(packet_path), pagesize=A4)\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "\n",
    "    # Coordinates must match the template layout (same y positions)\n",
    "    x_field = 250\n",
    "    y_start = height - 130\n",
    "    line_height = 40\n",
    "\n",
    "    fields_order = [\n",
    "        \"Passport No\", \"Name\", \"Nationality\", \"Date of Birth\",\n",
    "        \"Place of Issue\", \"Issue Date\", \"Expiry Date\",\n",
    "        \"Profession\", \"Employer\", \"Country\"\n",
    "    ]\n",
    "\n",
    "    for i, field in enumerate(fields_order):\n",
    "        y = y_start - i * line_height\n",
    "        value = data.get(field, \"\")\n",
    "        c.drawString(x_field + 5, y - 10, str(value))\n",
    "\n",
    "    c.save()\n",
    "\n",
    "    # Merge overlay with template\n",
    "    overlay_reader = PdfReader(str(packet_path))\n",
    "    overlay_page = overlay_reader.pages[0]\n",
    "    page.merge_page(overlay_page)\n",
    "    writer.add_page(page)\n",
    "\n",
    "    with open(output_pdf_path, \"wb\") as f:\n",
    "        writer.write(f)\n",
    "\n",
    "    Path(packet_path).unlink(missing_ok=True)\n",
    "    print(f\"âœ… Filled passport saved at: {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_pdf = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\passport_filled.pdf\")\n",
    "fill_passport_template(template_pdf, filled_pdf, mapped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdaa1ba",
   "metadata": {},
   "source": [
    "fill form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0918ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: pdf2image in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (1.17.0)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.5-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from ollama) (2.12.3)\n",
      "Requirement already satisfied: pillow in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from pdf2image) (12.0.0)\n",
      "Requirement already satisfied: anyio in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ai projects\\passport_extraction\\venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading pymupdf-1.26.5-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 4.5/18.7 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 11.8/18.7 MB 25.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.0/18.7 MB 25.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.7/18.7 MB 23.6 MB/s eta 0:00:00\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2, pymupdf\n",
      "\n",
      "   ---------------------------------------- 0/2 [PyPDF2]\n",
      "   ---------------------------------------- 0/2 [PyPDF2]\n",
      "   ---------------------------------------- 0/2 [PyPDF2]\n",
      "   ---------------------------------------- 0/2 [PyPDF2]\n",
      "   ---------------------------------------- 0/2 [PyPDF2]\n",
      "   ---------------------------------------- 0/2 [PyPDF2]\n",
      "   ---------------------------------------- 0/2 [PyPDF2]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   ---------------------------------------- 2/2 [pymupdf]\n",
      "\n",
      "Successfully installed PyPDF2-3.0.1 pymupdf-1.26.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install ollama pdf2image pymupdf PyPDF2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caebd36",
   "metadata": {},
   "source": [
    "fill form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded Extracted JSON Keys:\n",
      "- ID Number / Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©\n",
      "- File No / Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù\n",
      "- Passport No / Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ø²\n",
      "- Name / Ø§Ù„Ø§Ø³Ù…\n",
      "- Profession / Ø§Ù„Ù…Ù‡Ù†Ø©\n",
      "- Employer / ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„\n",
      "- Place of Issue / Ø¬Ù‡Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±\n",
      "- Issue Date / ØªØ§Ø±ÙŠØ® Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\n",
      "- Expiry Date / ØªØ§Ø±ÙŠØ® Ø¥Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\n",
      "- Country / Ø§Ù„Ø¯ÙˆÙ„Ø©\n",
      "- Type / Ù†ÙˆØ¹ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\n",
      "\n",
      "ğŸ“„ Converted 7 pages to images for LLM analysis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from io import BytesIO\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# === File Paths ===\n",
    "empty_form_pdf = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\23.pdf\")\n",
    "json_file = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\VISA_61734560.json\")\n",
    "\n",
    "# Load extracted JSON data\n",
    "with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    extracted_data = data.get(\"extracted_data\", data)\n",
    "\n",
    "print(\" Loaded Extracted JSON Keys:\")\n",
    "for k in extracted_data.keys():\n",
    "    print(\"-\", k)\n",
    "\n",
    "# === Convert ALL Pages of the Empty PDF to Images ===\n",
    "pages = convert_from_path(str(empty_form_pdf), dpi=150)\n",
    "page_images = []\n",
    "for p in pages:\n",
    "    buf = BytesIO()\n",
    "    p.save(buf, format=\"JPEG\")\n",
    "    page_images.append(buf.getvalue())\n",
    "\n",
    "print(f\"\\nğŸ“„ Converted {len(page_images)} pages to images for LLM analysis.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f823ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Processing Page 1...\n",
      "ğŸ” Processing Page 2...\n",
      "ğŸ” Processing Page 3...\n",
      "ğŸ” Processing Page 4...\n",
      "ğŸ” Processing Page 5...\n",
      "ğŸ” Processing Page 6...\n",
      "ğŸ” Processing Page 7...\n",
      "\n",
      "âœ… Finished detecting all field coordinates from all pages!\n",
      "\n",
      "{\n",
      "  \"page_1\": {\n",
      "    \"File Number (For Office Use Only)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 180\n",
      "    },\n",
      "    \"Name / Ø§Ù„Ø§Ø³Ù…\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 420\n",
      "    }\n",
      "  },\n",
      "  \"page_2\": {\n",
      "    \"2.4 Date of Birth (DD-MM-YYYY)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 180\n",
      "    },\n",
      "    \"2.5 Place of Birth (Village or Town or City)\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 420\n",
      "    },\n",
      "    \"2.6 Gender\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 660\n",
      "    },\n",
      "    \"2.7 Marital Status\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 720\n",
      "    },\n",
      "    \"2.8 Citizenship of India\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 780\n",
      "    },\n",
      "    \"2.9 PAN (If available)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 840\n",
      "    },\n",
      "    \"2.10 Voter ID (If available)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 900\n",
      "    },\n",
      "    \"2.11 Employment Type\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1040\n",
      "    },\n",
      "    \"2.12 If employed in Government/Statutory Body/PSU, specify organization name\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1100\n",
      "    },\n",
      "    \"2.13 Is either of your parent (in case of minor)/spouse, a government servant?\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1160\n",
      "    },\n",
      "    \"2.14 Educational Qualification\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1220\n",
      "    },\n",
      "    \"2.15 Are you eligible for Non-ECR category?\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1280\n",
      "    },\n",
      "    \"2.16 Visible Distinguishing Mark\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1340\n",
      "    },\n",
      "    \"2.17 Aadhaar Number\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1400\n",
      "    },\n",
      "    \"3. Family Details\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1540\n",
      "    }\n",
      "  },\n",
      "  \"page_3\": {\n",
      "    \"File Number (For Office Use Only)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 180\n",
      "    },\n",
      "    \"Name / Ø§Ù„Ø§Ø³Ù…\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 420\n",
      "    },\n",
      "    \"Father's Given Name (Given Name means First name followed by Middle name (If any)) (Initials not allowed)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 100\n",
      "    },\n",
      "    \"Surname\": {\n",
      "      \"x\": 450,\n",
      "      \"y\": 400\n",
      "    },\n",
      "    \"Mother's Given Name (Given Name means First name followed by Middle name (If any)) (Initials not allowed)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 200\n",
      "    },\n",
      "    \"Legal Guardian's Given Name (If applicable) (Initials not allowed)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 300\n",
      "    },\n",
      "    \"Spouse's Given Name (Given Name means First name followed by Middle name (If any)) (Initials not allowed)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 400\n",
      "    },\n",
      "    \"If applicant is minor, provide following details\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 500\n",
      "    },\n",
      "    \"Parent's Passport Details (If passport has been applied for but not received, give File Number)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 600\n",
      "    },\n",
      "    \"Father/ Legal Guardian's File/ Passport Number\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 700\n",
      "    },\n",
      "    \"Father/ Legal Guardian's Nationality, if not Indian\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 800\n",
      "    },\n",
      "    \"Mother/ Legal Guardian's File/ Passport Number\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 900\n",
      "    },\n",
      "    \"Mother/ Legal Guardian's Nationality, if not Indian\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1000\n",
      "    }\n",
      "  },\n",
      "  \"page_4\": {\n",
      "    \"Present Residential Address Details (Where applicant presently resides)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 180\n",
      "    },\n",
      "    \"House No. and Street Name\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 420\n",
      "    },\n",
      "    \"Village or Town or City\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 560\n",
      "    },\n",
      "    \"District\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 700\n",
      "    },\n",
      "    \"State/ UT\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 840\n",
      "    },\n",
      "    \"Mobile Number\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1580\n",
      "    },\n",
      "    \"Telephone Number\": {\n",
      "      \"x\": 500,\n",
      "      \"y\": 1580\n",
      "    },\n",
      "    \"E-mail ID\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1720\n",
      "    },\n",
      "    \"Is permanent address same as present address?\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1260\n",
      "    },\n",
      "    \"Emergency Contact Details\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1400\n",
      "    },\n",
      "    \"Name and Address\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1440\n",
      "    }\n",
      "  },\n",
      "  \"page_5\": {\n",
      "    \"File Number (For Office Use Only)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 180\n",
      "    },\n",
      "    \"Name of passport office where applied\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 580\n",
      "    }\n",
      "  },\n",
      "  \"page_6\": {\n",
      "    \"7.3 Provide the following details if the applicant has been refused/denied passport.\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 180\n",
      "    },\n",
      "    \"7.3.1 Have you ever been refused/denied passport?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 420\n",
      "    },\n",
      "    \"7.3.2 Has your passport ever been impounded?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 560\n",
      "    },\n",
      "    \"7.3.3 Has your passport ever been revoked?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 700\n",
      "    },\n",
      "    \"7.4 Provide the following details if applicant has applied for or been granted foreign citizenship.\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 840\n",
      "    },\n",
      "    \"7.4.1 Have you ever been granted citizenship by any other region/country?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 980\n",
      "    },\n",
      "    \"7.4.2 Have you ever held the passport of any other region/country at any time?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1120\n",
      "    },\n",
      "    \"7.4.3 Have you ever surrendered your Indian passport?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1260\n",
      "    },\n",
      "    \"7.4.4 Have you ever applied for renunciation of Indian citizenship?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1400\n",
      "    },\n",
      "    \"7.5 Provide the following details if applicant has returned to India on Emergency Certificate Certificate.\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 1540\n",
      "    },\n",
      "    \"7.5.1 Have you ever returned to India on Emergency Certificate (EC)?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1680\n",
      "    },\n",
      "    \"7.5.2 Have you ever been deported from any country?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1820\n",
      "    },\n",
      "    \"7.5.3 Have you ever been repatriated from any country back to India?\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1960\n",
      "    }\n",
      "  },\n",
      "  \"page_7\": {\n",
      "    \"8. Fee Details (Not to be filled by applicants submitting the application at Passport Seva Kendra)\": {\n",
      "      \"x\": 220,\n",
      "      \"y\": 180\n",
      "    },\n",
      "    \"8.1 Fee amount in (Rs)\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 420\n",
      "    },\n",
      "    \"8.2 If paid by Demand Draft (DD), provide the following details\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 450\n",
      "    },\n",
      "    \"DD Number\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 480\n",
      "    },\n",
      "    \"DD Issue Date\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 510\n",
      "    },\n",
      "    \"DD Expiry Date\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 540\n",
      "    },\n",
      "    \"Bank Name\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 570\n",
      "    },\n",
      "    \"Branch\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 600\n",
      "    },\n",
      "    \"9. Enclosures\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 630\n",
      "    },\n",
      "    \"10. Self Declaration\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 660\n",
      "    },\n",
      "    \"I owe allegiance to the sovereignty, unity & integrity of India, and have not voluntarily acquired citizenship or travel document of any other country\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 690\n",
      "    },\n",
      "    \"I have not lost, surrendered or been deprived of the citizenship of India\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 720\n",
      "    },\n",
      "    \"I have not contravened any of the conditions relating to the possession and use of an Indian passport\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 750\n",
      "    },\n",
      "    \"I affirm that the information and particulars given by me in this form are true and correct\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 780\n",
      "    },\n",
      "    \"I further state that I am not suppressing any material information in this regard\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 810\n",
      "    },\n",
      "    \"I further affirm that the enclosures and documentary proof submitted in support of my application for an Indian passport are authentic and solely pertain to me\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 840\n",
      "    },\n",
      "    \"I am fully responsible for the accuracy of the same\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 870\n",
      "    },\n",
      "    \"I am liable to be penalized or prosecuted if found otherwise\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 900\n",
      "    },\n",
      "    \"I am aware that under the Passports Act, 1967 it is a criminal offence to furnish any false information or to suppress any material information with a view to obtaining passport or travel document\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 930\n",
      "    },\n",
      "    \"I have read and understood the contents of the above and by submitting this form certify that all the information submitted by me in the form is bonafide\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 960\n",
      "    },\n",
      "    \"Place\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1000\n",
      "    },\n",
      "    \"Signature/ Left Hand Thumb Impression of Applicant (If applicant is minor, either parent to sign)\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1030\n",
      "    },\n",
      "    \"Date (DD-MM-YYYY)\": {\n",
      "      \"x\": 250,\n",
      "      \"y\": 1060\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === Analyze Each Page with Qwen2.5-VL ===\n",
    "all_fields = {}\n",
    "\n",
    "for i, img_bytes in enumerate(page_images):\n",
    "    print(f\"ğŸ” Processing Page {i+1}...\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in reading document layouts.\n",
    "    The uploaded image is page {i+1} of an EMPTY Indian passport form.\n",
    "\n",
    "    Task:\n",
    "    - Identify every field label (like File Number, Name, Country, Profession, etc.).\n",
    "    - Output their coordinates in pixels relative to the top-left corner.\n",
    "    - Keep both Arabic and English text exactly as visible.\n",
    "    - Output must be JSON only.\n",
    "\n",
    "    Format:\n",
    "    {{\n",
    "      \"fields\": {{\n",
    "        \"File Number (For Office Use Only)\": {{ \"x\": 220, \"y\": 180 }},\n",
    "        \"Name / Ø§Ù„Ø§Ø³Ù…\": {{ \"x\": 250, \"y\": 420 }}\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    Image size is 150 DPI.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"qwen2.5vl:7b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt, \"images\": [img_bytes]}],\n",
    "    )\n",
    "\n",
    "    content = response[\"message\"][\"content\"]\n",
    "    match = re.search(r\"(\\{[\\s\\S]*\\})\", content)\n",
    "    fields_info = json.loads(match.group(1)) if match else {}\n",
    "\n",
    "    all_fields[f\"page_{i+1}\"] = fields_info.get(\"fields\", {})\n",
    "\n",
    "print(\"\\nâœ… Finished detecting all field coordinates from all pages!\\n\")\n",
    "print(json.dumps(all_fields, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d2b093a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Total PDF fields detected: 79\n",
      "\n",
      "âœ… LLM Field Mapping:\n",
      "{\n",
      "  \"ID Number / Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©\": \"2.17 Aadhaar Number\",\n",
      "  \"File No / Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù\": \"File Number (For Office Use Only)\",\n",
      "  \"Passport No / Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ø²\": \"2.12 If employed in Government/Statutory Body/PSU, specify organization name\",\n",
      "  \"Name / Ø§Ù„Ø§Ø³Ù…\": \"Name / Ø§Ù„Ø§Ø³Ù…\",\n",
      "  \"Profession / Ø§Ù„Ù…Ù‡Ù†Ø©\": \"2.11 Employment Type\",\n",
      "  \"Employer / ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„\": \"2.12 If employed in Government/Statutory Body/PSU, specify organization name\",\n",
      "  \"Place of Issue / Ø¬Ù‡Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±\": \"Name of passport office where applied\",\n",
      "  \"Issue Date / ØªØ§Ø±ÙŠØ® Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"Date (DD-MM-YYYY)\",\n",
      "  \"Expiry Date / ØªØ§Ø±ÙŠØ® Ø¥Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"Date (DD-MM-YYYY)\",\n",
      "  \"Country / Ø§Ù„Ø¯ÙˆÙ„Ø©\": \"Country / Region\",\n",
      "  \"Type / Ù†ÙˆØ¹ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©\": \"2.15 Are you eligible for Non-ECR category?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# === Get all PDF field names (from multi-page detection) ===\n",
    "# If you ran the multi-page detection earlier, use `all_fields`\n",
    "# Otherwise, for single page, you can still use `fields_info`\n",
    "all_pdf_fields = []\n",
    "\n",
    "if \"all_fields\" in locals():\n",
    "    # Multi-page form: collect all unique field names from all pages\n",
    "    for page_num, fields_dict in all_fields.items():\n",
    "        all_pdf_fields.extend(list(fields_dict.keys()))\n",
    "else:\n",
    "    # Single page fallback\n",
    "    all_pdf_fields = list(fields_info.get(\"fields\", {}).keys())\n",
    "\n",
    "print(f\" Total PDF fields detected: {len(all_pdf_fields)}\")\n",
    "\n",
    "# === Prepare Matching Prompt ===\n",
    "prompt = f\"\"\"\n",
    "You are a form-field mapping assistant.\n",
    "\n",
    "I have two lists:\n",
    "1ï¸âƒ£ JSON keys (from extracted passport or visa data)\n",
    "2ï¸âƒ£ PDF field labels (from the empty passport form)\n",
    "\n",
    "Your job:\n",
    "- Match each JSON key to the most appropriate PDF field label, even if the wording differs.\n",
    "- Be flexible with synonyms (e.g., \"File No\" â‰ˆ \"File Number\", \"Name\" â‰ˆ \"Applicant's Given Name\").\n",
    "- Output valid JSON only â€” no explanations.\n",
    "\n",
    "Example:\n",
    "{{\n",
    "  \"File No / Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù\": \"File Number (For Office Use Only)\",\n",
    "  \"Name / Ø§Ù„Ø§Ø³Ù…\": \"Applicant's Given Name\",\n",
    "  \"Profession / Ø§Ù„Ù…Ù‡Ù†Ø©\": \"Profession\",\n",
    "  \"Country / Ø§Ù„Ø¯ÙˆÙ„Ø©\": \"Country / Region\"\n",
    "}}\n",
    "\n",
    "JSON keys: value \n",
    "{list(extracted_data.keys())}\n",
    "\n",
    "PDF fields:\n",
    "{all_pdf_fields}\n",
    "\"\"\"\n",
    "\n",
    "# === Use a Text Model for Better Matching (no image needed) ===\n",
    "response = ollama.chat(\n",
    "    model=\"qwen2.5vl:7b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    ")\n",
    "\n",
    "# === Extract JSON Safely from Response ===\n",
    "content = response[\"message\"][\"content\"]\n",
    "match = re.search(r\"(\\{[\\s\\S]*\\})\", content)\n",
    "field_map = json.loads(match.group(1)) if match else {}\n",
    "\n",
    "print(\"\\n LLM Field Mapping:\")\n",
    "print(json.dumps(field_map, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below code for convert empty pdf into html format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e43b85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved HTML file: output_from_pymupdf.html\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "pdf_path = r\"D:\\AI Projects\\passport_extraction\\passport\\23.pdf\"\n",
    "html_output = \"\"\n",
    "\n",
    "# Open the PDF\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Extract all pages as HTML\n",
    "for page_num, page in enumerate(doc, start=1):\n",
    "    html_output += f\"<!-- Page {page_num} -->\\n\"\n",
    "    html_output += page.get_text(\"html\")\n",
    "\n",
    "# Save HTML to file\n",
    "html_path = r\"output_from_pymupdf.html\"\n",
    "with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_output)\n",
    "\n",
    "print(f\"âœ… Saved HTML file: {html_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb86139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e06074f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b54552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c921732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523b674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e36a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama, json, re\n",
    "from pdf2image import convert_from_path\n",
    "from io import BytesIO\n",
    "\n",
    "def pdf_to_images_bytes(pdf_path):\n",
    "    pages = convert_from_path(pdf_path, dpi=150)\n",
    "    img_bytes = []\n",
    "    for page in pages:\n",
    "        buf = BytesIO()\n",
    "        page.save(buf, format=\"JPEG\")\n",
    "        img_bytes.append(buf.getvalue())\n",
    "    return img_bytes\n",
    "\n",
    "\n",
    "def extract_and_map_passport(pdf_path, model=\"qwen2.5vl:7b\"):\n",
    "    print(\"ğŸ“„ Extracting and mapping passport data...\")\n",
    "\n",
    "    schema = {\n",
    "        \"PassportNumber\": \"\",\n",
    "        \"Surname\": \"\",\n",
    "        \"GivenNames\": \"\",\n",
    "        \"DateOfBirth\": \"\",\n",
    "        \"PlaceOfBirth\": \"\",\n",
    "        \"Nationality\": \"\",\n",
    "        \"Sex\": \"\",\n",
    "        \"DateOfIssue\": \"\",\n",
    "        \"DateOfExpiry\": \"\",\n",
    "        \"Authority\": \"\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert OCR + document understanding LLM.\n",
    "    Extract ALL data from the given passport image(s).\n",
    "    Then map each value to the following schema strictly:\n",
    "    {json.dumps(schema, indent=2)}\n",
    "\n",
    "    Rules:\n",
    "    - Keep Arabic and English text as seen (no translation).\n",
    "    - If a value appears in both Arabic and English, join with \" / \".\n",
    "    - If a field is not visible, keep it empty (\"\").\n",
    "    - Output only valid JSON matching the schema.\n",
    "    \"\"\"\n",
    "\n",
    "    images = pdf_to_images_bytes(pdf_path)\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt, \"images\": images}]\n",
    "    )\n",
    "\n",
    "    text = response[\"message\"][\"content\"]\n",
    "    match = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
    "    return json.loads(match.group()) if match else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93ede443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.pdfgen import canvas\n",
    "from pathlib import Path\n",
    "\n",
    "def create_passport_template(path=\"passport_template.pdf\"):\n",
    "    c = canvas.Canvas(path, pagesize=A4)\n",
    "    width, height = A4\n",
    "\n",
    "    c.setTitle(\"Passport Template\")\n",
    "\n",
    "    c.setFont(\"Helvetica-Bold\", 14)\n",
    "    c.drawCentredString(width / 2, height - 50, \"Passport Data Page\")\n",
    "\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    y = height - 100\n",
    "    fields = [\n",
    "        \"PassportNumber\", \"Surname\", \"GivenNames\", \"DateOfBirth\",\n",
    "        \"PlaceOfBirth\", \"Nationality\", \"Sex\", \"DateOfIssue\",\n",
    "        \"DateOfExpiry\", \"Authority\"\n",
    "    ]\n",
    "\n",
    "    for f in fields:\n",
    "        c.drawString(80, y, f + \":\")\n",
    "        c.line(200, y, 500, y)\n",
    "        y -= 30\n",
    "\n",
    "    c.save()\n",
    "    print(f\"âœ… Template created: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368e0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from io import BytesIO\n",
    "\n",
    "def fill_passport_template(json_data, template_pdf, output_pdf):\n",
    "    packet = BytesIO()\n",
    "    can = canvas.Canvas(packet, pagesize=A4)\n",
    "    can.setFont(\"Helvetica\", 10)\n",
    "\n",
    "    y = A4[1] - 100\n",
    "    for key, value in json_data.items():\n",
    "        can.drawString(200, y, value)\n",
    "        y -= 30\n",
    "\n",
    "    can.save()\n",
    "    packet.seek(0)\n",
    "\n",
    "    new_pdf = PdfReader(packet)\n",
    "    existing_pdf = PdfReader(template_pdf)\n",
    "    output = PdfWriter()\n",
    "\n",
    "    page = existing_pdf.pages[0]\n",
    "    page.merge_page(new_pdf.pages[0])\n",
    "    output.add_page(page)\n",
    "\n",
    "    with open(output_pdf, \"wb\") as f:\n",
    "        output.write(f)\n",
    "\n",
    "    print(f\"âœ… Filled PDF created: {output_pdf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91339f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Extracting and mapping passport data...\n",
      "{\n",
      "  \"PassportNumber\": \"\",\n",
      "  \"Surname\": \"\",\n",
      "  \"GivenNames\": \"\",\n",
      "  \"DateOfBirth\": \"\",\n",
      "  \"PlaceOfBirth\": \"\",\n",
      "  \"Nationality\": \"\",\n",
      "  \"Sex\": \"\",\n",
      "  \"DateOfIssue\": \"\",\n",
      "  \"DateOfExpiry\": \"\",\n",
      "  \"Authority\": \"\"\n",
      "}\n",
      "âœ… Filled PDF created: D:\\AI Projects\\passport_extraction\\passport\\filled_passport.pdf\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "pdf_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\2.In house PL 31.03.2025.pdf\")\n",
    "template_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\passport_template_empty.pdf\")\n",
    "output_path = Path(r\"D:\\AI Projects\\passport_extraction\\passport\\filled_passport.pdf\")\n",
    "\n",
    "# Step 1: LLM extract + map\n",
    "data = extract_and_map_passport(pdf_path)\n",
    "print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Step 2: Fill template\n",
    "fill_passport_template(data, template_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71841bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt, RGBColor, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "def create_stylish_bank_template(path: str = \"stylish_bank_template.docx\"):\n",
    "    doc = Document()\n",
    "\n",
    "    # --- Title ---\n",
    "    title = doc.add_paragraph(\"Federal Bank - Account Opening Form\")\n",
    "    title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    title.runs[0].font.size = Pt(18)\n",
    "    title.runs[0].font.bold = True\n",
    "    title.runs[0].font.color.rgb = RGBColor(0, 51, 153)  # Navy blue\n",
    "\n",
    "    doc.add_paragraph(\"\")  # blank line for spacing\n",
    "\n",
    "    # --- Subtitle ---\n",
    "    subtitle = doc.add_paragraph(\"Please provide your personal details accurately. All fields are mandatory.\")\n",
    "    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    subtitle.runs[0].font.size = Pt(10)\n",
    "    subtitle.runs[0].font.color.rgb = RGBColor(80, 80, 80)\n",
    "\n",
    "    doc.add_paragraph(\"\")  # blank line for spacing\n",
    "\n",
    "    # --- Add Table for Information ---\n",
    "    table = doc.add_table(rows=5, cols=2)\n",
    "    table.style = \"Table Grid\"\n",
    "    table.autofit = True\n",
    "\n",
    "    fields = [\n",
    "        (\"Full Name\", \"{{name}}\"),\n",
    "        (\"Age\", \"{{age}}\"),\n",
    "        (\"Address\", \"{{address}}\"),\n",
    "        (\"Account Number\", \"{{account_number}}\"),\n",
    "        (\"IFSC Code\", \"{{ifsc_code}}\")\n",
    "    ]\n",
    "\n",
    "    for i, (label, placeholder) in enumerate(fields):\n",
    "        cell_label = table.cell(i, 0)\n",
    "        cell_label.text = label\n",
    "        for run in cell_label.paragraphs[0].runs:\n",
    "            run.font.bold = True\n",
    "            run.font.size = Pt(11)\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)\n",
    "        cell_value = table.cell(i, 1)\n",
    "        cell_value.text = placeholder\n",
    "        for run in cell_value.paragraphs[0].runs:\n",
    "            run.font.size = Pt(11)\n",
    "            run.font.color.rgb = RGBColor(50, 50, 50)\n",
    "\n",
    "    doc.add_paragraph(\"\")  # spacing\n",
    "\n",
    "    # --- Declaration ---\n",
    "    declaration = doc.add_paragraph(\n",
    "        \"I hereby declare that the above information provided is true and correct to the best of my knowledge.\"\n",
    "    )\n",
    "    declaration.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "    declaration.runs[0].font.size = Pt(11)\n",
    "\n",
    "    doc.add_paragraph(\"\")  # spacing\n",
    "\n",
    "    # --- Signature Section ---\n",
    "    signature_table = doc.add_table(rows=1, cols=2)\n",
    "    signature_table.style = \"Table Grid\"\n",
    "    signature_table.autofit = True\n",
    "    signature_table.cell(0, 0).text = \"Signature of Applicant: ___________________________\"\n",
    "    signature_table.cell(0, 1).text = \"Date: ___________________\"\n",
    "\n",
    "    # --- Footer ---\n",
    "    doc.add_paragraph(\"\")  # blank line\n",
    "    footer = doc.add_paragraph(\"Federal Bank Ltd Â© 2025 | Confidential Document\")\n",
    "    footer.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    for run in footer.runs:\n",
    "        run.font.size = Pt(9)\n",
    "        run.font.color.rgb = RGBColor(120, 120, 120)\n",
    "\n",
    "    doc.save(path)\n",
    "    print(f\"[ğŸ’] Stylish bank form template created successfully â†’ {path}\")\n",
    "\n",
    "create_stylish_bank_template()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
